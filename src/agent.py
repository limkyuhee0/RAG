import os
import json 
from dotenv import load_dotenv
from datasets import load_dataset
from tqdm import tqdm
from collections import Counter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

class RAGEvaluator:
    def __init__(self, db_path="data/vector_db", model="gpt-4o-mini", use_optimization=False):
        """
        RAG ê¸°ë°˜ QA + KMMLU í‰ê°€ í†µí•© í´ë˜ìŠ¤

        Args:
        - db_path (str): FAISS ë²¡í„° DB ê²½ë¡œ
        - model (str): OpenAI LLM ëª¨ë¸ (ê¸°ë³¸ê°’: "gpt-4o-mini")
        - use_optimization (bool): Self-Consistency ì ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        """
        load_dotenv()
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.use_optimization = use_optimization

        # ğŸ”¹ OpenAI LLM ì„¤ì •
        self.llm = ChatOpenAI(model=model, openai_api_key=self.api_key)

        # ğŸ”¹ FAISS ë²¡í„° DB ë¡œë“œ
        self.vectorstore = FAISS.load_local(
            db_path,
            OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=self.api_key),
            allow_dangerous_deserialization=True
        )
        self.retriever = self.vectorstore.as_retriever()

        # ğŸ”¹ KMMLU ë°ì´í„° ë¡œë“œ
        self.dataset = load_dataset("HAERAE-HUB/KMMLU", "Criminal-Law")["test"]

    def retrieve_documents(self, query, top_k=3):
        """
        ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜

        Args:
        - query (str): ì‚¬ìš©ì ì§ˆë¬¸
        - top_k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)

        Returns:
        - str: ê²€ìƒ‰ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸ (ê²°í•©ëœ í˜•íƒœ)
        """
        related_docs = self.retriever.invoke(query)
        retrieved_texts = "\n".join([doc.page_content for doc in related_docs[:top_k]])
        return retrieved_texts

    def format_kmmlu_question(self, example):
        """
        KMMLU ë°ì´í„°ì…‹ì„ GPTê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
        - example (dict): KMMLU ë¬¸ì œ ë°ì´í„°

        Returns:
        - str: GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ í˜•ì‹ì˜ ì§ˆë¬¸
        """
        question = example['question']
        options = [f"({i+1}) {example[opt]}" for i, opt in enumerate(["A", "B", "C", "D"])]
        formatted_text = f"{question}\n" + "\n".join(options)
        return formatted_text

    def generate_answer(self, example):
        """
        ë²¡í„° ê²€ìƒ‰ í›„ GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ 4ì§€ ì„ ë‹¤í˜• ë‹µë³€ ìƒì„±

        Args:
        - example (dict): KMMLU ë¬¸ì œ ë°ì´í„°

        Returns:
        - str: GPTê°€ ì„ íƒí•œ ì •ë‹µ (1, 2, 3, 4 ì¤‘ í•˜ë‚˜)
        """
        formatted_question = self.format_kmmlu_question(example)
        retrieved_texts = self.retrieve_documents(example["question"])

        prompt = f"""
        ğŸ” ì°¸ê³  ë¬¸ì„œ:
        {retrieved_texts}

        â“ ì§ˆë¬¸:
        {formatted_question}

        ğŸ¯ ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì£¼ì–´ì§„ ì„ íƒì§€ ì¤‘ì—ì„œ ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ **ë‹¨ í•˜ë‚˜ì˜ ìˆ«ì (1, 2, 3, 4)ë¡œë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
        """
        prompt = prompt.strip()
        response = self.llm.invoke(prompt).content.strip()

        # âœ… GPTê°€ ì‘ë‹µí•œ ê°’ì´ 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ì¸ì§€ í™•ì¸ í›„ ë°˜í™˜
        valid_choices = {"1", "2", "3", "4"}
        return response if response in valid_choices else "N/A"

    def evaluate_sample(self, index=0):
        """
        íŠ¹ì • KMMLU ë¬¸ì œ í•˜ë‚˜ë¥¼ í‰ê°€í•˜ê³  ê²€ìƒ‰ ê²°ê³¼ ë° ì‘ë‹µì„ ì¶œë ¥

        Args:
        - index (int): í‰ê°€í•  ë¬¸ì œì˜ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: 0)
        """
        example = self.dataset[index]
        retrieved_texts = self.retrieve_documents(example["question"])
        formatted_question = self.format_kmmlu_question(example)

        print("\nğŸ” **ê²€ìƒ‰ëœ ë¬¸ì„œ** ğŸ”")
        print(retrieved_texts)

        print("\nâ“ **KMMLU ë¬¸ì œ (í¬ë§·ëœ ì§ˆë¬¸)** â“")
        print(formatted_question)

        # GPT ì‘ë‹µ ì–»ê¸°
        answer = self.generate_answer(example)
        correct_answer = str(example["answer"])

        print("\nğŸ¤– **GPTì˜ ì„ íƒ**:", answer)
        print("âœ… **ì •ë‹µ (KMMLU ì œê³µ)**:", correct_answer)

        # ì •ë‹µ ì—¬ë¶€ í™•ì¸
        if answer == correct_answer:
            print("\nğŸ¯ **ì •ë‹µ!** âœ…")
        else:
            print("\nâŒ **ì˜¤ë‹µ!** âŒ")

    def evaluate_kmmlu(self):
        """
        KMMLU Criminal-Law ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ í‰ê°€ ìˆ˜í–‰

        Returns:
        - float: ìµœì¢… Accuracy
        """
        responses_per_question = []
        num_iterations = 5 if self.use_optimization else 1  # Self-Consistency ì ìš© ì—¬ë¶€

        # for example in tqdm(self.dataset, desc="Processing KMMLU Evaluation"):
        for idx, example in enumerate(tqdm(self.dataset, desc="Processing KMMLU Evaluation", disable=False)): 
            print(f"ğŸ“ [{idx+1}/{len(self.dataset)}] ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {example['question']}")  
            question_responses = []

            for _ in range(num_iterations):
                answer = self.generate_answer(example)
                question_responses.append(answer.strip())

            # Self-Consistency ì ìš©: ìµœë¹ˆê°’ ì„ íƒ
            final_answer = Counter(question_responses).most_common(1)[0][0] if self.use_optimization else question_responses[0]
            responses_per_question.append(final_answer)

        # ì •ë‹µ ë¹„êµ ë° Accuracy ê³„ì‚°
        correct_answers = [str(example["answer"]) for example in self.dataset]  # KMMLU ì •ë‹µì€ ìˆ«ì ë¬¸ìì—´
        accuracy = sum(1 for gt, pred in zip(correct_answers, responses_per_question) if gt == pred) / len(correct_answers) * 100

        # í‰ê°€ ê²°ê³¼ ì €ì¥
        score_path = f"output/kmmlu_score{'_optimized' if self.use_optimization else ''}.txt"
        # âœ… ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(os.path.dirname(score_path), exist_ok=True)
        with open(score_path, "w") as f:
            f.write(f"KMMLU Criminal-Law Score: {accuracy:.2f}%\n")

        print(f"ğŸ¯ KMMLU Criminal-Law Score: {accuracy:.2f}% (Optimized: {self.use_optimization})")
        return accuracy

    def save_batch_io(self, batch_input_path="batch_input.jsonl", batch_output_path="batch_output.jsonl"):
        """
        KMMLU ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•´ batch APIì— ì‚¬ìš©ëœ input (í”„ë¡¬í”„íŠ¸ ë“±)ê³¼ 
        output (ëª¨ë¸ì˜ ì‘ë‹µ)ì„ JSONL íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        Args:
        - batch_input_path (str): ì €ì¥í•  batch input JSONL íŒŒì¼ ê²½ë¡œ
        - batch_output_path (str): ì €ì¥í•  batch output JSONL íŒŒì¼ ê²½ë¡œ
        """
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ë‹¤ë©´ ìƒì„±
        os.makedirs(os.path.dirname(batch_input_path) or ".", exist_ok=True)
        os.makedirs(os.path.dirname(batch_output_path) or ".", exist_ok=True)

        with open(batch_input_path, "w", encoding="utf-8") as fin, open(batch_output_path, "w", encoding="utf-8") as fout:
            for example in tqdm(self.dataset, desc="Saving batch IO"):
                formatted_question = self.format_kmmlu_question(example)
                retrieved_texts = self.retrieve_documents(example["question"])
                prompt = f"""
                ğŸ” ì°¸ê³  ë¬¸ì„œ:
                {retrieved_texts}

                â“ ì§ˆë¬¸:
                {formatted_question}

                ğŸ¯ ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì£¼ì–´ì§„ ì„ íƒì§€ ì¤‘ì—ì„œ ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ **ë‹¨ í•˜ë‚˜ì˜ ìˆ«ì (1, 2, 3, 4)ë¡œë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
                """
                prompt = prompt.strip()

                # ëª¨ë¸ í˜¸ì¶œ ë° ì‘ë‹µ
                response = self.llm.invoke(prompt).content.strip()
                valid_choices = {"1", "2", "3", "4"}
                answer = response if response in valid_choices else "N/A"

                # batch input ì •ë³´ êµ¬ì„±
                input_data = {
                    "question": example["question"],
                    "formatted_question": formatted_question,
                    "retrieved_documents": retrieved_texts,
                    "prompt": prompt
                }
                # batch output ì •ë³´ êµ¬ì„±
                output_data = {
                    "response": answer
                }
                # JSONL íŒŒì¼ì— í•œ ì¤„ì”© ê¸°ë¡
                fin.write(json.dumps(input_data, ensure_ascii=False) + "\n")
                fout.write(json.dumps(output_data, ensure_ascii=False) + "\n")

if __name__ == "__main__":
    evaluator = RAGEvaluator(use_optimization=True)  # Self-Consistency ì‚¬ìš©

    # âœ… íŠ¹ì • ë°ì´í„° ìƒ˜í”Œ í‰ê°€
    evaluator.evaluate_sample(index=0)

    # âœ… ì „ì²´ KMMLU ë°ì´í„°ì…‹ í‰ê°€
    evaluator.evaluate_kmmlu()

    # âœ… batch input, output ì •ë³´ë¥¼ JSONL íŒŒì¼ë¡œ ì €ì¥
    evaluator.save_batch_io(batch_input_path="output/batch_input.jsonl", batch_output_path="output/batch_output.jsonl")
